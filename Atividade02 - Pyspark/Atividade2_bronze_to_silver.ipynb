{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06268d1a-a86f-447e-84e8-f70579144562",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<h1>Importa√ß√£o</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02afff9f-8733-49c6-9f7c-76a7b9b64312",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StringType, DecimalType, DoubleType ,TimestampType , LongType, IntegerType,DateType\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd2a69ad-cd68-4014-9fbd-4c532d4abb59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalogo = \"medalhao\"\n",
    "bronze_db_name = \"bronze\"\n",
    "silver_db_name = \"silver\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d64fc5d9-f7e3-46ad-8c5c-fea1ffb59da0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<h1>FUN√á√ÉO AUXILIAR PARA ESCRITA NA CAMADA SILVER‚úçÔ∏èü•à</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69532078-988d-46d8-8253-9c9fd4c92e8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def write_to_silver(df, table_name, partition_by=None):\n",
    "  \n",
    "    full_table_name = f\"{catalogo}.{silver_db_name}.{table_name}\"\n",
    "    \n",
    "    writer = df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\")\n",
    "    \n",
    "    if partition_by:\n",
    "        writer = writer.partitionBy(*partition_by)\n",
    "        \n",
    "    writer.saveAsTable(full_table_name)\n",
    "    \n",
    "    print(f\"Tabela Silver {full_table_name} criada/atualizada com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd16f120-142f-4266-8426-2c4aad9d664b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<h1>Transforma√ß√µesüí£</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b288d7c-bfc8-4e8e-a3ca-a672aab7efda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "COLUMNS_FT_CONSUMIDORES = {\n",
    "    \"customer_id\": \"id_consumidor\",\n",
    "    \"customer_zip_code_prefix\": \"prefixo_cep\",\n",
    "    \"customer_city\": \"cidade\",\n",
    "    \"customer_state\": \"estado\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    df_consumidores_bronze = spark.table(f\"{catalogo}.{bronze_db_name}.ft_consumidores\")\n",
    "    \n",
    "    # 1. Sele√ß√£o e Padroniza√ß√£o de Nomes\n",
    "    df_consumidores_silver = df_consumidores_bronze.select(\n",
    "        *[F.col(col_orig).alias(col_dest) for col_orig, col_dest in COLUMNS_FT_CONSUMIDORES.items()]\n",
    "    )\n",
    "    \n",
    "    # 2. Upper Case para Cidade/Estado\n",
    "    df_consumidores_silver = df_consumidores_silver.withColumn(\n",
    "        \"cidade\", F.upper(F.col(\"cidade\"))\n",
    "    ).withColumn(\n",
    "        \"estado\", F.upper(F.col(\"estado\"))\n",
    "    )\n",
    "    \n",
    "    # 3. Remo√ß√£o de Duplicatas em id_consumidor\n",
    "    num_registros_originais = df_consumidores_silver.count()\n",
    "    df_consumidores_silver = df_consumidores_silver.dropDuplicates([\"id_consumidor\"])\n",
    "    num_registros_apos_distinct = df_consumidores_silver.count()\n",
    "    \n",
    "    print(f\" Registros originais: {num_registros_originais}\")\n",
    "    print(f\" Registros ap√≥s remo√ß√£o de duplicatas (id_consumidor): {num_registros_apos_distinct}\")\n",
    "    \n",
    "    # 4. Escrita na Camada Silver\n",
    "    write_to_silver(df_consumidores_silver, \"ft_consumidores\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao processar ft_consumidores: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d657910c-5ec7-4ce6-8529-4ea7dcd38a32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- INICIANDO TRANSFORMA√á√ÉO: ft_pedidos ---\")\n",
    "\n",
    "try:\n",
    "    df_pedidos_bronze = spark.table(f\"{catalogo}.{bronze_db_name}.ft_pedidos\")\n",
    "    \n",
    "    STATUS_MAPPING = {\n",
    "        \"delivered\": \"entregue\", \"invoiced\": \"faturado\", \"shipped\": \"enviado\",\n",
    "        \"processing\": \"em processamento\", \"unavailable\": \"indispon√≠vel\",\n",
    "        \"canceled\": \"cancelado\", \"created\": \"criado\", \"approved\": \"aprovado\"\n",
    "    }\n",
    "    \n",
    "    df_pedidos_silver = df_pedidos_bronze.select(\n",
    "        F.col(\"order_id\").alias(\"id_pedido\"),\n",
    "        F.col(\"customer_id\").alias(\"id_consumidor\"),\n",
    "        F.col(\"order_purchase_timestamp\").cast(TimestampType()).alias(\"pedido_compra_timestamp\"),\n",
    "        F.col(\"order_approved_at\").cast(TimestampType()).alias(\"pedido_aprovado_timestamp\"),\n",
    "        F.col(\"order_delivered_carrier_date\").cast(TimestampType()).alias(\"pedido_carregado_timestamp\"),\n",
    "        F.col(\"order_delivered_customer_date\").cast(TimestampType()).alias(\"pedido_entregue_timestamp\"),\n",
    "        F.col(\"order_estimated_delivery_date\").cast(TimestampType()).alias(\"pedido_estimativa_entrega_timestamp\"),\n",
    "        F.col(\"order_status\").alias(\"status_pedido_en\")\n",
    "    )\n",
    "    \n",
    "    case_expression_status = F.col(\"status_pedido_en\")\n",
    "    for en, pt in STATUS_MAPPING.items():\n",
    "        case_expression_status = F.when(case_expression_status == en, F.lit(pt)).otherwise(case_expression_status)\n",
    "    \n",
    "    df_pedidos_silver = df_pedidos_silver.withColumn(\n",
    "        \"status\", case_expression_status\n",
    "    ).drop(\"status_pedido_en\")\n",
    "    \n",
    "    SEGUNDOS_POR_DIA = 60 * 60 * 24\n",
    "    \n",
    "    df_pedidos_silver = df_pedidos_silver.withColumn(\n",
    "        \"tempo_entrega_dias\",\n",
    "        F.round(\n",
    "            (F.col(\"pedido_entregue_timestamp\").cast(LongType()) - F.col(\"pedido_compra_timestamp\").cast(LongType())) / SEGUNDOS_POR_DIA,\n",
    "            2\n",
    "        ).cast(DoubleType())\n",
    "    )\n",
    "    \n",
    "    df_pedidos_silver = df_pedidos_silver.withColumn(\n",
    "        \"tempo_entrega_estimado_dias\",\n",
    "        F.round(\n",
    "            (F.col(\"pedido_estimativa_entrega_timestamp\").cast(LongType()) - F.col(\"pedido_compra_timestamp\").cast(LongType())) / SEGUNDOS_POR_DIA,\n",
    "            2\n",
    "        ).cast(DoubleType())\n",
    "    )\n",
    "    \n",
    "    df_pedidos_silver = df_pedidos_silver.withColumn(\n",
    "        \"diferenca_entrega_dias\",\n",
    "        F.round(F.col(\"tempo_entrega_dias\") - F.col(\"tempo_entrega_estimado_dias\"), 2)\n",
    "    )\n",
    "    \n",
    "    df_pedidos_silver = df_pedidos_silver.withColumn(\n",
    "        \"entrega_no_prazo\",\n",
    "        F.when(F.col(\"status\") != F.lit(\"entregue\"), F.lit(\"N√£o Entregue\"))\n",
    "        .when(F.col(\"diferenca_entrega_dias\") <= 0, F.lit(\"Sim\"))\n",
    "        .otherwise(F.lit(\"N√£o\"))\n",
    "    )\n",
    "\n",
    "    df_pedidos_silver = df_pedidos_silver.select(\n",
    "        \"id_pedido\",\n",
    "        \"id_consumidor\",\n",
    "        \"status\",\n",
    "        \"pedido_compra_timestamp\",\n",
    "        \"pedido_aprovado_timestamp\",\n",
    "        \"pedido_carregado_timestamp\",\n",
    "        \"pedido_entregue_timestamp\",\n",
    "        \"pedido_estimativa_entrega_timestamp\",\n",
    "        \"tempo_entrega_dias\",\n",
    "        \"tempo_entrega_estimado_dias\",\n",
    "        \"diferenca_entrega_dias\",\n",
    "        \"entrega_no_prazo\"\n",
    "    )\n",
    "    \n",
    "    write_to_silver(df_pedidos_silver, \"ft_pedidos\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao processar ft_pedidos: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a36204fe-a8a9-400e-b3d7-bee4967a0d83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- INICIANDO TRANSFORMA√á√ÉO: ft_itens_pedidos ---\")\n",
    "\n",
    "COLUMNS_FT_ITENS = {\n",
    "    \"order_id\": \"id_pedido\",\n",
    "    \"order_item_id\": \"id_item\",\n",
    "    \"product_id\": \"id_produto\",\n",
    "    \"seller_id\": \"id_vendedor\",\n",
    "    \"price\": \"preco_BRL\",\n",
    "    \"freight_value\": \"preco_frete\",\n",
    "}\n",
    "\n",
    "try:\n",
    "    df_itens_bronze = spark.table(f\"{catalogo}.{bronze_db_name}.ft_itens_pedidos\")\n",
    "    \n",
    "    # 1. Sele√ß√£o, Padroniza√ß√£o de Nomes e Tipagem\n",
    "    df_itens_silver = df_itens_bronze.select(\n",
    "        *[F.col(col_orig).alias(col_dest) for col_orig, col_dest in COLUMNS_FT_ITENS.items()],\n",
    "    ).withColumn(\n",
    "        \"preco_BRL\", F.col(\"preco_BRL\").cast(DecimalType(12, 2))\n",
    "    ).withColumn(\n",
    "        \"preco_frete\", F.col(\"preco_frete\").cast(DecimalType(12, 2))\n",
    "    )  \n",
    "    # 2. Escrita na Camada Silver\n",
    "    write_to_silver(df_itens_silver, \"ft_itens_pedidos\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao processar ft_itens_pedidos: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fadd0bc2-e7ac-4cbb-835f-0e2db8c72086",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- INICIANDO TRANSFORMA√á√ÉO: ft_pagamentos_pedidos ---\")\n",
    "\n",
    "PAYMENT_TYPE_MAPPING = {\n",
    "    \"credit_card\": \"Cart√£o de Cr√©dito\",\n",
    "    \"boleto\": \"Boleto\",\n",
    "    \"voucher\": \"Voucher\",\n",
    "    \"debit_card\": \"Cart√£o de D√©bito\",\n",
    "}\n",
    "\n",
    "try:\n",
    "    df_pagamentos_bronze = spark.table(f\"{catalogo}.{bronze_db_name}.ft_pagamentos_pedidos\")\n",
    "    \n",
    "    df_pagamentos_silver = df_pagamentos_bronze.select(\n",
    "        F.col(\"order_id\").alias(\"id_pedido\"),\n",
    "        F.col(\"payment_sequential\").cast(IntegerType()).alias(\"codigo_pagamento\"),\n",
    "        F.col(\"payment_type\").alias(\"forma_pagamento_en\"),\n",
    "        F.col(\"payment_installments\").cast(IntegerType()).alias(\"parcelas\"),\n",
    "        F.col(\"payment_value\").cast(DecimalType(12, 2)).alias(\"valor_pagamento\"),\n",
    "        F.col(\"ingestion_timestamp\").cast(TimestampType()).alias(\"data_ingestao\")\n",
    "    )\n",
    "    \n",
    "    case_expression_payment = F.when(F.col(\"forma_pagamento_en\") == F.lit(\"credit_card\"), F.lit(\"Cart√£o de Cr√©dito\"))\n",
    "\n",
    "    for en, pt in PAYMENT_TYPE_MAPPING.items():\n",
    "        if en != \"credit_card\": \n",
    "            case_expression_payment = case_expression_payment.when(F.col(\"forma_pagamento_en\") == F.lit(en), F.lit(pt))\n",
    "    \n",
    "    df_pagamentos_silver = df_pagamentos_silver.withColumn(\n",
    "        \"forma_pagamento\", case_expression_payment.otherwise(F.lit(\"Outro\"))\n",
    "    ).drop(\"forma_pagamento_en\")\n",
    "    \n",
    "    df_pagamentos_silver = df_pagamentos_silver.select(\n",
    "        \"id_pedido\",\n",
    "        \"codigo_pagamento\",\n",
    "        \"forma_pagamento\",\n",
    "        \"parcelas\",\n",
    "        \"valor_pagamento\",\n",
    "    )\n",
    "    \n",
    "    write_to_silver(df_pagamentos_silver, \"ft_pagamentos_pedidos\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao processar ft_pagamentos_pedidos: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28aa9879-61d1-49fd-b514-bb48e339a1ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Transforma√ß√£o: `ft_avaliacoes_pedidos` (Camada Silver)\n",
    "\n",
    "\n",
    "####Regras de Valida√ß√£o Aplicadas\n",
    "\n",
    "| Regra | Campo | Condi√ß√£o | Motivo / A√ß√£o |\n",
    "|:------|:------|:----------|:---------------|\n",
    "| **R1** | `id_pedido` | `IS NULL` | ID de pedido ausente ou inv√°lido. Registro removido. |\n",
    "| **R2** | `data_comentario` | `IS NULL` | Data de cria√ß√£o do coment√°rio ausente. Registro removido. |\n",
    "| **R3** | `data_comentario` | `> current_timestamp()` | Data de coment√°rio no futuro. Registro removido. |\n",
    "| **R4** | `avaliacao` | `IS NULL` (ap√≥s `try_cast`) | Valor de avalia√ß√£o inv√°lido (ex.: texto onde deveria haver n√∫mero). Registro removido. |\n",
    "\n",
    "---\n",
    "\n",
    "####Tratamento de Tipos\n",
    "\n",
    "Para garantir consist√™ncia e evitar erros durante o processamento, as convers√µes foram feitas de forma **segura**, utilizando fun√ß√µes SQL do Spark que convertem valores malformados em `NULL`:\n",
    "\n",
    "- `try_cast(avaliacao AS INT)` ‚Üí evita erro se o valor n√£o for num√©rico.  \n",
    "- `try_to_timestamp(data_comentario)` e `try_to_timestamp(data_resposta)` ‚Üí convertem strings de data malformadas para `NULL`.\n",
    "\n",
    "Esses `NULL` resultantes s√£o tratados pelas regras **R2** e **R4** acima.\n",
    "\n",
    "---\n",
    "\n",
    "####M√©tricas de Limpeza\n",
    "\n",
    "Durante a execu√ß√£o do processo, s√£o exibidos no console:\n",
    "\n",
    "- `Registros originais:` n√∫mero total antes da filtragem  \n",
    "- `Registros removidos:` quantidade de linhas inv√°lidas descartadas  \n",
    "\n",
    "Esses indicadores permitem validar a integridade e o impacto da limpeza aplicada.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Resultado Esperado\n",
    "Ap√≥s a transforma√ß√£o, a tabela `ft_avaliacoes_pedidos` na camada **Silver** deve conter apenas registros v√°lidos, com:\n",
    "- IDs de pedido v√°lidos,\n",
    "- Datas coerentes,\n",
    "- E avalia√ß√µes num√©ricas consistentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64a80760-0af7-445c-86c6-32fcb4c2589d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- INICIANDO TRANSFORMA√á√ÉO: ft_avaliacoes_pedidos ---\")\n",
    "\n",
    "COLUMNS_FT_AVALIACOES = {\n",
    "    \"review_id\": \"id_avaliacao\",\n",
    "    \"order_id\": \"id_pedido\",\n",
    "    \"review_score\": \"avaliacao\",\n",
    "    \"review_comment_title\": \"titulo_comentario\",\n",
    "    \"review_comment_message\": \"comentario\",\n",
    "    \"review_creation_date\": \"data_comentario\",\n",
    "    \"review_answer_timestamp\": \"data_resposta\",\n",
    "}\n",
    "\n",
    "try:\n",
    "    df_avaliacoes_bronze = spark.table(f\"{catalogo}.{bronze_db_name}.ft_avaliacoes_pedidos\")\n",
    "    \n",
    "    # 1. Sele√ß√£o e Padroniza√ß√£o de Nomes\n",
    "    df_avaliacoes_silver = df_avaliacoes_bronze.select(\n",
    "        *[F.col(col_orig).alias(col_dest) for col_orig, col_dest in COLUMNS_FT_AVALIACOES.items()],\n",
    "        \n",
    "    )\n",
    "    \n",
    "    # 2. Tipagem (Data e Score)\n",
    "    # Usa F.expr com try_cast e try_to_timestamp \n",
    "    df_avaliacoes_silver = (\n",
    "        df_avaliacoes_silver\n",
    "        .withColumn(\"avaliacao\", F.expr(\"try_cast(avaliacao as int)\"))\n",
    "        .withColumn(\"data_comentario\", F.expr(\"try_to_timestamp(data_comentario)\"))\n",
    "        .withColumn(\"data_resposta\", F.expr(\"try_to_timestamp(data_resposta)\"))\n",
    "    )\n",
    "    \n",
    "    # 3. Regras de Valida√ß√£o e Remo√ß√£o de Registros Inv√°lidos\n",
    "    current_timestamp_spark = F.current_timestamp()\n",
    "\n",
    "    filtro_invalido = (\n",
    "        F.col(\"id_pedido\").isNull() | \n",
    "        F.col(\"data_comentario\").isNull() |\n",
    "        (F.col(\"data_comentario\") > current_timestamp_spark) |\n",
    "        F.col(\"avaliacao\").isNull()\n",
    "    )\n",
    "    \n",
    "    num_registros_originais = df_avaliacoes_silver.count()\n",
    "    \n",
    "    df_avaliacoes_silver = df_avaliacoes_silver.filter(~filtro_invalido)\n",
    "    \n",
    "    num_registros_removidos = num_registros_originais - df_avaliacoes_silver.count()\n",
    "    \n",
    "    print(f\"\\n--- DETALHES DA VALIDA√á√ÉO (ft_avaliacoes_pedidos) ---\")\n",
    "    print(f\" Registros originais: {num_registros_originais}\")\n",
    "    print(f\" Registros removidos: {num_registros_removidos}\")\n",
    "    \n",
    "    # 4. Escrita na Camada Silver\n",
    "    write_to_silver(df_avaliacoes_silver, \"ft_avaliacoes_pedidos\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao processar ft_avaliacoes_pedidos: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d66802cc-1c86-4461-b68e-b0b8d22689b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- INICIANDO TRANSFORMA√á√ÉO: ft_produtos ---\")\n",
    "\n",
    "COLUMNS_FT_PRODUTOS = {\n",
    "    \"product_id\": \"id_produto\",\n",
    "    \"product_category_name\": \"categoria_produto\",\n",
    "    \"product_weight_g\": \"peso_produto_gramas\",\n",
    "    \"product_length_cm\": \"comprimento_centimetros\",\n",
    "    \"product_height_cm\": \"altura_centimetros\",\n",
    "    \"product_width_cm\": \"largura_centimetros\",\n",
    "}\n",
    "\n",
    "try:\n",
    "    df_produtos_bronze = spark.table(f\"{catalogo}.{bronze_db_name}.ft_produtos\")\n",
    "    \n",
    "    # 1. Sele√ß√£o, Padroniza√ß√£o de Nomes e Tipagem\n",
    "    df_produtos_silver = df_produtos_bronze.select(\n",
    "        *[F.col(col_orig).alias(col_dest) for col_orig, col_dest in COLUMNS_FT_PRODUTOS.items()],\n",
    "    ).withColumn(\n",
    "        \"peso_produto_gramas\", F.col(\"peso_produto_gramas\").cast(IntegerType())\n",
    "    ).withColumn(\n",
    "        \"comprimento_centimetros\", F.col(\"comprimento_centimetros\").cast(IntegerType())\n",
    "    ).withColumn(\n",
    "        \"altura_centimetros\", F.col(\"altura_centimetros\").cast(IntegerType())\n",
    "    ).withColumn(\n",
    "        \"largura_centimetros\", F.col(\"largura_centimetros\").cast(IntegerType())\n",
    "    )\n",
    "    \n",
    "    # 2. Escrita na Camada Silver\n",
    "    write_to_silver(df_produtos_silver, \"ft_produtos\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao processar ft_produtos: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42d5baa8-f2f1-4f86-bf33-93e12d14fbbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- INICIANDO TRANSFORMA√á√ÉO: ft_vendedores ---\")\n",
    "\n",
    "COLUMNS_FT_VENDEDORES = {\n",
    "    \"seller_id\": \"id_vendedor\",\n",
    "    \"seller_zip_code_prefix\": \"prefixo_cep\",\n",
    "    \"seller_city\": \"cidade\",\n",
    "    \"seller_state\": \"estado\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    df_vendedores_bronze = spark.table(f\"{catalogo}.{bronze_db_name}.ft_vendedores\")\n",
    "    \n",
    "    # 1. Sele√ß√£o e Padroniza√ß√£o de Nomes\n",
    "    df_vendedores_silver = df_vendedores_bronze.select(\n",
    "        *[F.col(col_orig).alias(col_dest) for col_orig, col_dest in COLUMNS_FT_VENDEDORES.items()],\n",
    "    )\n",
    "    \n",
    "    # 2. Upper Case para Cidade/Estado\n",
    "    df_vendedores_silver = df_vendedores_silver.withColumn(\n",
    "        \"cidade\", F.upper(F.col(\"cidade\"))\n",
    "    ).withColumn(\n",
    "        \"estado\", F.upper(F.col(\"estado\"))\n",
    "    )\n",
    "    \n",
    "    # 3. Escrita na Camada Silver\n",
    "    write_to_silver(df_vendedores_silver, \"ft_vendedores\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao processar ft_vendedores: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c742f766-7024-49c1-9672-2e418695f080",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- INICIANDO TRANSFORMA√á√ÉO: dm_categoria_produtos_traducao ---\")\n",
    "\n",
    "COLUMNS_DM_CATEGORIA = {\n",
    "    \"product_category_name\": \"nome_produto_pt\",\n",
    "    \"product_category_name_english\": \"nome_produto_en\",\n",
    "}\n",
    "\n",
    "try:\n",
    "    df_categoria_bronze = spark.table(f\"{catalogo}.{bronze_db_name}.dm_categoria_produtos_traducao\")\n",
    "    \n",
    "    # 1. Sele√ß√£o e Padroniza√ß√£o de Nomes\n",
    "    df_categoria_silver = df_categoria_bronze.select(\n",
    "        *[F.col(col_orig).alias(col_dest) for col_orig, col_dest in COLUMNS_DM_CATEGORIA.items()],\n",
    "    )\n",
    "    \n",
    "    # 2. Escrita na Camada Silver\n",
    "    write_to_silver(df_categoria_silver, \"dm_categoria_produtos_traducao\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao processar dm_categoria_produtos_traducao: {str(e)}\")\n",
    "COLUMNS_DM_CATEGORIA = {\n",
    "    \"product_category_name\": \"nome_produto_pt\",\n",
    "    \"product_category_name_english\": \"nome_produto_en\",\n",
    "}\n",
    "\n",
    "try:\n",
    "    df_categoria_bronze = spark.table(f\"{catalogo}.{bronze_db_name}.dm_categoria_produtos_traducao\")\n",
    "    \n",
    "    # 1. Sele√ß√£o e Padroniza√ß√£o de Nomes\n",
    "    df_categoria_silver = df_categoria_bronze.select(\n",
    "        *[F.col(col_orig).alias(col_dest) for col_orig, col_dest in COLUMNS_DM_CATEGORIA.items()],\n",
    "    )\n",
    "    \n",
    "    # 2. Escrita na Camada Silver\n",
    "    write_to_silver(df_categoria_silver, \"dm_categoria_produtos_traducao\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao processar dm_categoria_produtos_traducao: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ef4b24c-ade0-4afb-b665-5a721df0467d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- INICIANDO TRANSFORMA√á√ÉO: dm_cotacao_dolar ---\")\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, DateType, DecimalType, TimestampType\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime\n",
    "\n",
    "COLUMNS_DM_COTACAO = {\n",
    "    \"dataHoraCotacao\": \"data_cotacao_raw\",\n",
    "    \"cotacaoCompra\": \"cotacao_dolar\",\n",
    "}\n",
    "\n",
    "try:\n",
    "   \n",
    "    df_cotacao_bronze = spark.table(f\"{catalogo}.{bronze_db_name}.dm_cotacao_dolar\")\n",
    "\n",
    "    # Renomear colunas relevantes\n",
    "    df_cotacao_silver = df_cotacao_bronze.select(\n",
    "        *[F.col(col_orig).alias(col_dest) for col_orig, col_dest in COLUMNS_DM_COTACAO.items()]\n",
    "    )\n",
    "\n",
    "\n",
    "    df_cotacao_silver = (\n",
    "        df_cotacao_silver\n",
    "        .withColumn(\"data\", F.to_date(F.col(\"data_cotacao_raw\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "        .withColumn(\"cotacao_dolar\", F.col(\"cotacao_dolar\").cast(DecimalType(12, 4)))\n",
    "        .drop(\"data_cotacao_raw\")\n",
    "    )\n",
    "\n",
    "    # Preencher cota√ß√£o faltante pela √∫ltima conhecida\n",
    "    window_spec = Window.partitionBy(F.lit(1)).orderBy(\"data\")\n",
    "    df_cotacao_silver = df_cotacao_silver.withColumn(\n",
    "        \"cotacao_dolar_preenchida\",\n",
    "        F.last(F.col(\"cotacao_dolar\"), True).over(window_spec)\n",
    "    )\n",
    "\n",
    "    data_inicio = \"2016-01-01\"\n",
    "    data_fim = \"2018-12-31\"\n",
    "    dias_total = (datetime.strptime(data_fim, \"%Y-%m-%d\") - datetime.strptime(data_inicio, \"%Y-%m-%d\")).days\n",
    "\n",
    "    df_datas = (\n",
    "        spark.range(0, dias_total + 1)\n",
    "        .withColumn(\"data\", F.date_add(F.lit(data_inicio), F.col(\"id\").cast(\"int\")))\n",
    "        .select(\"data\")\n",
    "    )\n",
    "\n",
    "\n",
    "    df_cotacao_completa = df_datas.join(\n",
    "        df_cotacao_silver.select(\"data\", \"cotacao_dolar_preenchida\"),\n",
    "        on=\"data\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Preencher lacunas restantes com √∫ltimo valor conhecido\n",
    "    window_spec_full = Window.partitionBy(F.lit(1)).orderBy(\"data\")\n",
    "    df_cotacao_final = (\n",
    "        df_cotacao_completa\n",
    "        .withColumn(\"cotacao_dolar_final\", F.last(F.col(\"cotacao_dolar_preenchida\"), True).over(window_spec_full))\n",
    "        .select(\n",
    "            F.col(\"cotacao_dolar_final\").alias(\"cotacao_dolar\"),\n",
    "            F.col(\"data\")  \n",
    "        )\n",
    "    )\n",
    "\n",
    " \n",
    "    write_to_silver(df_cotacao_final, \"dm_cotacao_dolar\")\n",
    "\n",
    "    print(\"‚úÖ Transforma√ß√£o dm_cotacao_dolar conclu√≠da e salva na Silver.\")\n",
    "    display(df_cotacao_final.orderBy(F.desc(\"data\")).limit(10))\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    if \"is not a table or view\" in str(e) or \"Cannot resolve table\" in str(e):\n",
    "        print(\"‚ö†Ô∏è A tabela dm_cotacao_dolar da Bronze n√£o existe ou est√° inacess√≠vel. Criando tabela Silver vazia.\")\n",
    "        empty_schema = StructType([\n",
    "            StructField(\"data\", DateType(), True),\n",
    "            StructField(\"cotacao_dolar\", DecimalType(12, 4), True),\n",
    "            StructField(\"data_ingestao\", TimestampType(), True)\n",
    "        ])\n",
    "        df_empty = spark.createDataFrame(spark.sparkContext.emptyRDD(), empty_schema)\n",
    "        write_to_silver(df_empty, \"dm_cotacao_dolar\")\n",
    "    else:\n",
    "        print(f\"‚ùå Erro ao processar dm_cotacao_dolar: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e21eb285-072a-4f61-bfba-fde5b158fd4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<h1> Verifica√ß√£o de orf√£os</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03e13bed-3cbb-4909-96cf-f8be33d9f759",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- VERIFICA√á√ÉO E REMO√á√ÉO DE REGISTROS √ìRF√ÉOS ---\")\n",
    "\n",
    "try:\n",
    "    df_pedidos = spark.table(f\"{catalogo}.{silver_db_name}.ft_pedidos\")\n",
    "    df_consumidores = spark.table(f\"{catalogo}.{silver_db_name}.ft_consumidores\")\n",
    "    df_itens_pedidos = spark.table(f\"{catalogo}.{silver_db_name}.ft_itens_pedidos\")\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "    print(f\"Erro ao ler tabelas Silver: {str(e)}. Pule a valida√ß√£o de integridade.\")\n",
    "    df_pedidos = None\n",
    "\n",
    "if df_pedidos is not None:\n",
    "  \n",
    "    pedidos_sem_consumidor = df_pedidos.join(\n",
    "        df_consumidores.select(\"id_consumidor\"),\n",
    "        on=\"id_consumidor\",\n",
    "        how=\"left_anti\" \n",
    "    )\n",
    "    \n",
    "    count_pedidos_orfaos = pedidos_sem_consumidor.count()\n",
    "    print(f\"‚ö†Ô∏è Pedidos √≥rf√£os (sem 'id_consumidor' correspondente): {count_pedidos_orfaos}\")\n",
    "    \n",
    "    if count_pedidos_orfaos > 0:\n",
    "\n",
    "        # Remove os registros √≥rf√£os da tabela ft_pedidos\n",
    "\n",
    "        df_pedidos_limpos = df_pedidos.exceptAll(pedidos_sem_consumidor)\n",
    "        write_to_silver(df_pedidos_limpos, \"ft_pedidos\")\n",
    "\n",
    "        df_pedidos = df_pedidos_limpos # Atualiza o DF de pedidos para a pr√≥xima verifica√ß√£o\n",
    "        print(f\"Registros √≥rf√£os removidos de ft_pedidos. Nova contagem: {df_pedidos.count()}\")\n",
    "    \n",
    "\n",
    "    itens_sem_pedido = df_itens_pedidos.join(\n",
    "        df_pedidos.select(\"id_pedido\"), \n",
    "        on=\"id_pedido\",\n",
    "        how=\"left_anti\"\n",
    "    )\n",
    "    \n",
    "    count_itens_orfaos = itens_sem_pedido.count()\n",
    "    print(f\"‚ö†Ô∏è Itens √≥rf√£os (sem 'id_pedido' correspondente): {count_itens_orfaos}\")\n",
    "    \n",
    "    if count_itens_orfaos > 0:\n",
    "        # Remove os registros √≥rf√£os da tabela ft_itens_pedidos\n",
    "        df_itens_pedidos_limpos = df_itens_pedidos.exceptAll(itens_sem_pedido)\n",
    "        write_to_silver(df_itens_pedidos_limpos, \"ft_itens_pedidos\")\n",
    "        df_itens_pedidos = df_itens_pedidos_limpos # Atualiza o DF de itens para o pr√≥ximo passo\n",
    "        print(f\"‚úÖ Registros √≥rf√£os removidos de ft_itens_pedidos. Nova contagem: {df_itens_pedidos.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac79d3fd-31b7-4309-8d5e-05ce19d389f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<h1>Tabela Finalüìã</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8310c51-036f-43b5-bd06-4cf4344db684",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- CRIA√á√ÉO DA TABELA FINAL: ft_pedido_total ---\")\n",
    "\n",
    "try:\n",
    "    df_pedidos = spark.table(f\"{catalogo}.{silver_db_name}.ft_pedidos\")\n",
    "    df_consumidores = spark.table(f\"{catalogo}.{silver_db_name}.ft_consumidores\")\n",
    "    df_pagamentos = spark.table(f\"{catalogo}.{silver_db_name}.ft_pagamentos_pedidos\")\n",
    "    df_cotacao = spark.table(f\"{catalogo}.{silver_db_name}.dm_cotacao_dolar\")\n",
    "\n",
    "    df_pagamentos_agregados = (\n",
    "        df_pagamentos.groupBy(\"id_pedido\")\n",
    "        .agg(F.sum(\"valor_pagamento\").alias(\"valor_total_pago_brl\"))\n",
    "    )\n",
    "\n",
    "    df_final = (\n",
    "        df_pedidos\n",
    "        .join(df_consumidores.select(\"id_consumidor\", \"cidade\", \"estado\"), on=\"id_consumidor\", how=\"inner\")\n",
    "        .join(df_pagamentos_agregados, on=\"id_pedido\", how=\"inner\")\n",
    "    )\n",
    "\n",
    "    df_final = df_final.withColumn(\n",
    "        \"data_pedido\",\n",
    "        F.to_date(F.col(\"pedido_compra_timestamp\")).cast(DateType())\n",
    "    )\n",
    "\n",
    "    df_final_com_cotacao = df_final.join(\n",
    "        df_cotacao.select(\"data\", \"cotacao_dolar\"),\n",
    "        df_final[\"data_pedido\"] == df_cotacao[\"data\"],\n",
    "        \"left\"\n",
    "    )\n",
    "\n",
    "    df_pedido_total = df_final_com_cotacao.select(\n",
    "        F.col(\"data_pedido\").alias(\"data\"),\n",
    "        F.col(\"id_pedido\"),\n",
    "        F.col(\"id_consumidor\"),\n",
    "        F.col(\"status\"),\n",
    "        F.col(\"valor_total_pago_brl\"),\n",
    "        (F.col(\"valor_total_pago_brl\") / F.coalesce(F.col(\"cotacao_dolar\"), F.lit(1))).alias(\"valor_total_pago_usd\")\n",
    "    )\n",
    "\n",
    "    df_pedido_total = df_pedido_total.withColumn(\n",
    "        \"valor_total_pago_usd\",\n",
    "        F.col(\"valor_total_pago_usd\").cast(DecimalType(12, 2))\n",
    "    )\n",
    "\n",
    "    write_to_silver(df_pedido_total, \"ft_pedido_total\")\n",
    "\n",
    "    print(\"‚úÖ Tabela ft_pedido_total criada com sucesso (com convers√£o para USD).\")\n",
    "    display(df_pedido_total.limit(10))\n",
    "\n",
    "except Exception as e:\n",
    "    # Captura o erro e imprime a mensagem\n",
    "    print(f\"‚ùå Erro ao criar ft_pedido_total: {str(e)}\")\n",
    "\n",
    "print(\"\\n--- TODAS AS TRANSFORMA√á√ïES SILVER CONCLU√çDAS ---\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Atividade2_bronze_to_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
